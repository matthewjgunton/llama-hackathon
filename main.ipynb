{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in ./.venv/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: soundfile in ./.venv/lib/python3.12/site-packages (0.12.1)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in ./.venv/lib/python3.12/site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: torch==2.5.1 in ./.venv/lib/python3.12/site-packages (from torchaudio) (2.5.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.venv/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.venv/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sounddevice torchaudio soundfile ipywidgets transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495902a43f264a3d99b4cd0c7a12f590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Start Recording', style=ButtonStyle()), Label(value='Press button to start â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def record_audio_torchaudio_compatible(duration=5, samplerate=16_000, filename='recording.wav'):\n",
    "    \"\"\"\n",
    "    Record audio in a Jupyter notebook and save it as a WAV file.\n",
    "    Output format is compatible with `torchaudio.load`.\n",
    "    \n",
    "    Parameters:\n",
    "    duration (float): Recording duration in seconds\n",
    "    samplerate (int): Sample rate in Hz\n",
    "    filename (str): Output filename (must end in .wav)\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Recorded audio data in shape [channels, samples]\n",
    "    int: Original sample rate\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create widgets\n",
    "    record_button = widgets.Button(description=\"Start Recording\")\n",
    "    status_label = widgets.Label(value=\"Press button to start recording\")\n",
    "    audio_player_widget = widgets.Output()\n",
    "\n",
    "    recording_data = {'audio': None}\n",
    "\n",
    "    def on_button_click(b):\n",
    "        # Disable button and update status\n",
    "        record_button.disabled = True\n",
    "        status_label.value = f\"Recording for {duration} seconds...\"\n",
    "        \n",
    "        # Record audio\n",
    "        recording = sd.rec(\n",
    "            int(samplerate * duration),\n",
    "            samplerate=samplerate,\n",
    "            channels=1,\n",
    "            dtype='float32'  # Match `torchaudio` float32 format\n",
    "        )\n",
    "        sd.wait()  # Wait until recording is finished\n",
    "        \n",
    "        # Reshape to match `torchaudio` format [channels, samples]\n",
    "        recording = torch.tensor(recording.T)  # Transpose for [1, samples]\n",
    "        \n",
    "        # Save the recording\n",
    "        sf.write(filename, recording.numpy().T, samplerate)  # Convert back for saving\n",
    "        \n",
    "        # Store recording data\n",
    "        recording_data['audio'] = recording\n",
    "        \n",
    "        # Update status\n",
    "        status_label.value = f\"Recording saved to {filename}\"\n",
    "        \n",
    "        # Display the audio player\n",
    "        with audio_player_widget:\n",
    "            display(f\"Audio saved: {filename}\")\n",
    "        \n",
    "        # Enable button again\n",
    "        record_button.disabled = False\n",
    "\n",
    "    # Attach the button click event\n",
    "    record_button.on_click(on_button_click)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(widgets.VBox([record_button, status_label, audio_player_widget]))\n",
    "    \n",
    "    # Return audio data and sample rate after recording\n",
    "    def get_audio():\n",
    "        return recording_data['audio'], samplerate\n",
    "\n",
    "    return get_audio\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "get_audio = record_audio_torchaudio_compatible(duration=5, filename='my_recording.wav')\n",
    "\n",
    "# After recording, fetch audio and play\n",
    "audio, samplerate = get_audio()\n",
    "if audio is not None:\n",
    "    print(\"Audio shape:\", audio.shape)\n",
    "    print(\"Sample rate:\", samplerate)\n",
    "\"\"\"\n",
    "\n",
    "get_audio = record_audio_torchaudio_compatible(duration=5, filename='backup.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe057d104c084f6ba84bd5fda8be7952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation from audio: Hola, hola, mi nombre es Matthew.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, SeamlessM4Tv2Model\n",
    "import torchaudio\n",
    "\n",
    "audio, sample_rate = get_audio()\n",
    "\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "\n",
    "# audio =  torchaudio.functional.resample(audio, orig_freq=orig_freq, new_freq=16_000) # must be a 16 kHz waveform array\n",
    "audio_inputs = processor(audios=audio, return_tensors=\"pt\")\n",
    "\n",
    "## translate the audio\n",
    "output_tokens = model.generate(**audio_inputs, tgt_lang=\"spa\", generate_speech=False)\n",
    "translated_text_from_audio = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
    "print(f\"Translation from audio: {translated_text_from_audio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama Fact-Check?\n",
    "## our model is fairly big ~10GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do a quick inference and see if there are any red flags\n",
    "\n",
    "## protect family & friends from scams\n",
    "## key parts -> smaller & multi-lingual\n",
    "\n",
    "# maybe use llama stack here??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
